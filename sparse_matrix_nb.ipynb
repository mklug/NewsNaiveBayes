{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tests the implementation of Bernoulli naive Bayes given in ``sparse_matrix_nb_implementation.py``.  This implementation does a single read through the training data to both build the dictionary that associates the vocabulary/classes with indices as well as a sparse matrix that contains the estimates at the parameters.  The entries of this matrix must then be modified (to adjust for the total number of words in each class, the smoothing parameter $\\alpha$, and to take logarithms).  Care must be taken with the choice of sparse matrix representation to ensure (efficient) support for the needed operations.  In its logarithmic form, naive Bayes is a linear classifier and therefore prediction is done by first computing the feature vector from the input and then doing a matrix-vector multiplication.  In order to keep the matrix of parameters sparse, the $\\alpha$-smoothing for the $0$ entries is done by modifying the resulting vector accordingly.  \n",
    "\n",
    "More details can be found in ``sparse_matrix_nb_implementation.py``. \n",
    "\n",
    "Below we test this implementation first on a synthetic dataset and then on the Huffington Post dataset.  We see that the results agree exactly with the sklearn implementation of naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparse_matrix_nb_implemenation import BNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf.vocabulary={'this': 0, 'is': 1, 'an': 2, 'entry': 3, 'too': 4, 'so': 5}\n",
      "clf.Theta.toarray()=array([[-1.46633707, -1.46633707, -1.87180218, -1.87180218,  0.        ,\n",
      "        -1.87180218],\n",
      "       [-1.5040774 , -1.5040774 ,  0.        ,  0.        , -1.5040774 ,\n",
      "         0.        ]])\n",
      "clf.log_priors=array([-0.40546511, -1.09861229])\n",
      "clf.alpha=1.0\n",
      "clf.index_to_class={0: 'red', 1: 'blue'}\n",
      "clf.num_classes=2\n",
      "clf.num_words=6\n",
      "clf.class_index_to_word_count=Counter({0: 7, 1: 3})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['red', 'red', 'red', 'blue']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test case\n",
    "\n",
    "X_train = [\"this is an entry\\n\", \n",
    "          \"this is too\\n\", \n",
    "          \"so is this\\n\"]\n",
    "\n",
    "y_train = [\"red\",\n",
    "          \"blue\",\n",
    "          \"red\"]\n",
    "\n",
    "X_test = [\"this is an entry\\n\",\n",
    "          \"so this is\\n\",\n",
    "          \"hello\\n\",\n",
    "          \"this is too\\n\"]\n",
    "\n",
    "clf = BNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'{clf.vocabulary=}')\n",
    "print(f'{clf.Theta.toarray()=}')\n",
    "print(f'{clf.log_priors=}')\n",
    "print(f'{clf.alpha=}')\n",
    "print(f'{clf.index_to_class=}')\n",
    "print(f'{clf.num_classes=}')\n",
    "print(f'{clf.num_words=}')\n",
    "print(f'{clf.class_index_to_word_count=}')\n",
    "\n",
    "# entry for 'this' in 'red'\n",
    "# math.log((2.0 + 1.0)/(7.0 + 6.0*1.0))\n",
    "# entry for 'too' in 'blue'\n",
    "# math.log((1.0 + 1.0)/(3.0 + 6.0*1.0))\n",
    "clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM = 42\n",
    "PATH = \"data/News_Category_Dataset_v3.json\"\n",
    "cats = [\"POLITICS\", \"WELLNESS\", \"ENTERTAINMENT\", \"TRAVEL\", \"STYLE & BEAUTY\"]\n",
    "\n",
    "df = pd.read_json(PATH, lines=True)\n",
    "df = df[df.category.isin(cats)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(labels=[\"link\", \"authors\", \"date\"], axis=1, inplace=True)\n",
    "df[\"combined\"] = pd.Series([h + ' ' + d for h,d in zip(df[\"headline\"], df[\"short_description\"])], \n",
    "                                index=df[\"headline\"].index.copy())\n",
    "\n",
    "X_train, X_test = train_test_split(df, train_size=0.8, random_state=RANDOM, stratify=df[\"category\"])\n",
    "y_train, y_test = X_train[\"category\"], X_test[\"category\"]\n",
    "X_train.drop(labels=[\"category\"], axis=1, inplace=True)\n",
    "X_test.drop(labels=[\"category\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9019586206896552"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('nb', BernoulliNB())])\n",
    "\n",
    "clf.fit(X_train[\"combined\"], y_train)\n",
    "clf.predict(X_test[\"combined\"])\n",
    "np.mean(predicted == y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = BNB()\n",
    "my_clf.fit(X_train[\"combined\"], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9019586206896552"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = my_clf.predict(X_test[\"combined\"])\n",
    "np.mean(predicted == y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
